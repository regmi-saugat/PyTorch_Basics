{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c31b1ee",
   "metadata": {},
   "source": [
    "**Introduction to Linear Regression**\n",
    "\n",
    "The learning part of linear regression is to figure out a set of weights `w11, w12,... w23, b1 & b2` using the training data, to make accurate predictions for new data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79f84922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@ Loading the required libraries\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f667cf47",
   "metadata": {},
   "source": [
    "**Preparing the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82dfe871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******** Input (temp, rainfall, humidity) ********\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbe545fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ******** Targets (apples, oranges) ********\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ae49922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]])\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "#@ Converting inputs and targets to tensors\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed4f447",
   "metadata": {},
   "source": [
    "**Linear Regression model from scratch**\n",
    "\n",
    "The weights and biases (w11, w12,... w23, b1 & b2) can also be represented as matrices, initialized as random values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2417d3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1548, -0.7328,  0.2397],\n",
      "        [ 0.5012, -0.3079, -0.8642]], requires_grad=True)\n",
      "tensor([0.7990, 0.2215], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#@ Weights and biases\n",
    "w = torch.randn(2, 3, requires_grad=True)\n",
    "b = torch.randn(2, requires_grad=True)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe445a5",
   "metadata": {},
   "source": [
    "`torch.randn` creates a tensor with the given shape, with elements picked randomly from normal distribution with mean 0 and standard deviation as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aff33e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@ Defining the model\n",
    "def model(x):\n",
    "    return x @ w.t() + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b9f28d",
   "metadata": {},
   "source": [
    "- `@` represents matrix multiplication\n",
    "- `.t()` method returns the transpose of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ccf8cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-49.2899, -20.9859],\n",
      "        [-62.4307, -36.5802],\n",
      "        [-96.9573, -47.5642],\n",
      "        [-37.6307,   6.1243],\n",
      "        [-63.4490, -55.2552]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#@ Generating predictions\n",
    "preds = model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b231af81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "#@ Comparing the model\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe056cb6",
   "metadata": {},
   "source": [
    "**Loss Function**\n",
    "\n",
    "Before we improve our model, we need a way to evaluate how well our model is performing. We can compare the model's predictions with the actual targets using the following method:\n",
    "\n",
    "- Calculate the difference between the two matrices (preds and targets).\n",
    "- Square all elements of the difference matrix to remove negative values.\n",
    "- Calculate the average of the elements in the resulting matrix.\n",
    "\n",
    "The result is a single number, known as the mean squared error (MSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bbeb1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@ Mean Squared Error Loss\n",
    "def mse(t1, t2):\n",
    "    diff = t1 - t2\n",
    "    return torch.sum(diff*diff) / diff.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a2c9a5",
   "metadata": {},
   "source": [
    "- `torch.sum` returns sum of all elements of tensor\n",
    "- `numel` method of a tensor returns the number of elements in tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20e4e453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(20068.5293, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#@ Let's compute the loss\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db731ee",
   "metadata": {},
   "source": [
    "Hereâ€™s how we can interpret the result: *On average, each element in the prediction differs from the actual target by the square root of the loss*. The result is called the *loss* because it indicates how bad the model is at predicting the target variables. It represents information loss in the model: the lower the loss, the better the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099f01b5",
   "metadata": {},
   "source": [
    "**Compute Gradients**\n",
    "\n",
    "In PyTorch, we can automatically compute the gradient or derivative of the loss w.r.t. to the weights and biases because it have `requires_grad` set to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44a618e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@ Computing gradients\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697673e6",
   "metadata": {},
   "source": [
    "Those gradients are stored in `.grad` property of the respective tensors.\n",
    "\n",
    "*Note:* The derivative of the loss w.r.t. the weights matrix is itself a matrix with the same dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076543aa",
   "metadata": {},
   "source": [
    "**Adjusting weights and biases to reduce the loss**\n",
    "\n",
    "If a gradient element is positive:\n",
    "\n",
    "- increasing the weight element's value slightly will increase the loss\n",
    "- decreasing the weight element's value slightly will decrease the loss\n",
    "\n",
    "If a gradient element is negative:\n",
    "\n",
    "- increasing the weight element's value slightly will decrease the loss\n",
    "- decreasing the weight element's value slightly will increase the loss\n",
    "\n",
    "The increase or decrease in the loss by changing a weight element is proportional to the gradient of the loss w.r.t. that element. This observation forms the basis of the gradient descent optimization algorithm that we'll use to improve our model (by descending along the gradient)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74ddbb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1548, -0.7328,  0.2397],\n",
      "        [ 0.5012, -0.3079, -0.8642]], requires_grad=True)\n",
      "tensor([[-11418.7891, -13431.5635,  -8018.0635],\n",
      "        [-10008.7568, -12090.9736,  -7306.1025]])\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3e4f26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    w -= w.grad * 1e-5\n",
    "    b -= b.grad * 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206d4dd5",
   "metadata": {},
   "source": [
    "We multiply the gradients with a very small number (`10^-5` in this case) to ensure that we don't modify the weights by a very large amount. We want to take a small step in the downhill direction of the gradient, not a giant leap. This number is called the *learning rate* of the algorithm. \n",
    "\n",
    "We use `torch.no_grad` to indicate to PyTorch that we shouldn't track, calculate, or modify gradients while updating the weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccc2c8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(20068.5293, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#@ Let's verify that the loss is actually lower\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9cef59",
   "metadata": {},
   "source": [
    "Before we proceed, we reset the gradients to zero by invoking the `.zero_()` method. We need to do this because PyTorch accumulates gradients. Otherwise, the next time we invoke `.backward` on the loss, the new gradient values are added to the existing gradients, which may lead to unexpected results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfe95558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "w.grad.zero_()\n",
    "b.grad.zero_()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dec1b87",
   "metadata": {},
   "source": [
    "**Train the model using gradient descent**\n",
    "\n",
    "As seen above, we reduce the loss and improve our model using the gradient descent optimization algorithm. Thus, we can _train_ the model using the following steps:\n",
    "\n",
    "1. Generate predictions\n",
    "\n",
    "2. Calculate the loss\n",
    "\n",
    "3. Compute gradients w.r.t the weights and biases\n",
    "\n",
    "4. Adjust the weights by subtracting a small quantity proportional to the gradient\n",
    "\n",
    "5. Reset the gradients to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d50fc3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-28.5059,  -2.4357],\n",
      "        [-35.0869, -12.1550],\n",
      "        [-64.3728, -18.4159],\n",
      "        [-17.2399,  24.2368],\n",
      "        [-37.0617, -31.6263]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#@ Generate the predictions\n",
    "preds = model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "018c45a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13922.8984, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#@ Calculating the loss\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db67d2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -9270.5996, -11116.5469,  -6591.0264],\n",
      "        [ -8090.6318, -10021.9014,  -6030.9717]])\n",
      "tensor([-112.6534, -100.0792])\n"
     ]
    }
   ],
   "source": [
    "#@ Compute gradients\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adf7a7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0521, -0.4873,  0.3858],\n",
      "        [ 0.6822, -0.0868, -0.7309]], requires_grad=True)\n",
      "tensor([0.8015, 0.2237], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#@ Adjusting weights & reset gradients\n",
    "with torch.no_grad():\n",
    "    w -= w.grad * 1e-5\n",
    "    b -= b.grad * 1e-5\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "    \n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b073a06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@ Training for 100 epochs\n",
    "for i in range(100):\n",
    "    preds = model(inputs)\n",
    "    loss = mse(preds, targets)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= w.grad * 1e-5\n",
    "        b -= b.grad * 1e-5\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74f52c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(397.9607, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#@ Calculating loss\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "567824a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 62.3964,  77.4039],\n",
      "        [ 86.8037,  96.6783],\n",
      "        [ 99.8310, 130.6319],\n",
      "        [ 50.8120,  77.1475],\n",
      "        [ 92.7262,  88.8180]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "#@ Printing predictions and comparing with targets\n",
    "print(preds)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07eeec4",
   "metadata": {},
   "source": [
    "## Linear Regression using PyTorch built-ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e15538b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@ importing the package from pytorch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20dcbe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ********** Input (temp, rainfall, humidity) **********\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70], \n",
    "                   [74, 66, 43], \n",
    "                   [91, 87, 65], \n",
    "                   [88, 134, 59], \n",
    "                   [101, 44, 37], \n",
    "                   [68, 96, 71], \n",
    "                   [73, 66, 44], \n",
    "                   [92, 87, 64], \n",
    "                   [87, 135, 57], \n",
    "                   [103, 43, 36], \n",
    "                   [68, 97, 70]], \n",
    "                  dtype='float32')\n",
    "\n",
    "# ********** Targets (apples, oranges) **********\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119],\n",
    "                    [57, 69], \n",
    "                    [80, 102], \n",
    "                    [118, 132], \n",
    "                    [21, 38], \n",
    "                    [104, 118], \n",
    "                    [57, 69], \n",
    "                    [82, 100], \n",
    "                    [118, 134], \n",
    "                    [20, 38], \n",
    "                    [102, 120]], \n",
    "                   dtype='float32')\n",
    "\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "913dee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "953a65e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 73.,  67.,  43.],\n",
       "         [ 91.,  88.,  64.],\n",
       "         [ 87., 134.,  58.]]),\n",
       " tensor([[ 56.,  70.],\n",
       "         [ 81., 101.],\n",
       "         [119., 133.]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@ Defining dataset\n",
    "train_data = TensorDataset(inputs, targets)\n",
    "train_data[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2e947ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@ Defning dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 5\n",
    "train_dl = DataLoader(train_data, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "544e6c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 68.,  96.,  71.],\n",
      "        [ 74.,  66.,  43.],\n",
      "        [ 68.,  97.,  70.],\n",
      "        [101.,  44.,  37.],\n",
      "        [ 73.,  66.,  44.]])\n",
      "tensor([[104., 118.],\n",
      "        [ 57.,  69.],\n",
      "        [102., 120.],\n",
      "        [ 21.,  38.],\n",
      "        [ 57.,  69.]])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_dl:\n",
    "    print(xb)\n",
    "    print(yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e453e193",
   "metadata": {},
   "source": [
    "**`nn.Linear`**\n",
    "\n",
    "Instead of initializing the weights & biases manually, we can define the model using `nn.Linear` class from PyTorch which does it automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "164d39a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.5669,  0.0396,  0.2929],\n",
      "        [ 0.3753,  0.2228, -0.3838]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.3812, 0.0802], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#@ Defining the model\n",
    "model = nn.Linear(3, 2)\n",
    "print(model.weight)\n",
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95d98ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.5669,  0.0396,  0.2929],\n",
       "         [ 0.3753,  0.2228, -0.3838]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.3812, 0.0802], requires_grad=True)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@ Accessing parameters\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fae9e38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[57.0069, 25.9033],\n",
       "        [74.1916, 29.2782],\n",
       "        [71.9875, 40.3291],\n",
       "        [70.7391, 33.7430],\n",
       "        [63.7942, 20.5007],\n",
       "        [57.5342, 26.0558],\n",
       "        [74.4449, 28.6715],\n",
       "        [72.8472, 40.3206],\n",
       "        [70.2118, 33.5905],\n",
       "        [63.5202, 19.7416],\n",
       "        [57.2602, 25.2967],\n",
       "        [74.7189, 29.4307],\n",
       "        [71.7342, 40.9357],\n",
       "        [71.0131, 34.5021],\n",
       "        [63.2669, 20.3482]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@ Generating the predictions\n",
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "543df4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3159.3359, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#@ Defining loss function & compute the loss for the current predictions\n",
    "import torch.nn.functional as F\n",
    "loss_fn = F.mse_loss\n",
    "loss = loss_fn(model(inputs), targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20cd5b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@ Defining the optimizers\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0a8bbb",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "We are now ready to train the model. We'll follow the same process to implement gradient descent:\n",
    "\n",
    "1. Generate predictions\n",
    "\n",
    "2. Calculate the loss\n",
    "\n",
    "3. Compute gradients w.r.t the weights and biases\n",
    "\n",
    "4. Adjust the weights by subtracting a small quantity proportional to the gradient\n",
    "\n",
    "5. Reset the gradients to zero\n",
    "\n",
    "The only change is that we'll work batches of data instead of processing the entire training data in every iteration. Let's define a utility function `fit` that trains the model for a given number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f29c8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@ Function to train the model\n",
    "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
    "    for epoch in range(num_epochs):   # repeat given number of epochs\n",
    "        for xb, yb in train_dl:       # train with batches of data\n",
    "            pred = model(xb)          # generate predictions\n",
    "            loss = loss_fn(pred, yb)  # calculate the loss\n",
    "            loss.backward()           # computing gradients\n",
    "            opt.step()                # update parameter using gradients\n",
    "            opt.zero_grad()           # Reset the gradients to zero\n",
    "            if (epoch+1) % 10 == 0:   # print the progress\n",
    "                print('Epoch [{}/{}], Loss: {:4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a5ec804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 643.811096\n",
      "Epoch [10/100], Loss: 587.447754\n",
      "Epoch [10/100], Loss: 706.822205\n",
      "Epoch [20/100], Loss: 465.904724\n",
      "Epoch [20/100], Loss: 422.202728\n",
      "Epoch [20/100], Loss: 480.014740\n",
      "Epoch [30/100], Loss: 274.210907\n",
      "Epoch [30/100], Loss: 518.143921\n",
      "Epoch [30/100], Loss: 197.475891\n",
      "Epoch [40/100], Loss: 240.571091\n",
      "Epoch [40/100], Loss: 103.636192\n",
      "Epoch [40/100], Loss: 366.612305\n",
      "Epoch [50/100], Loss: 166.503311\n",
      "Epoch [50/100], Loss: 137.644608\n",
      "Epoch [50/100], Loss: 229.249512\n",
      "Epoch [60/100], Loss: 225.209198\n",
      "Epoch [60/100], Loss: 119.720825\n",
      "Epoch [60/100], Loss: 68.374771\n",
      "Epoch [70/100], Loss: 64.624939\n",
      "Epoch [70/100], Loss: 139.034409\n",
      "Epoch [70/100], Loss: 98.596786\n",
      "Epoch [80/100], Loss: 111.324112\n",
      "Epoch [80/100], Loss: 51.440758\n",
      "Epoch [80/100], Loss: 75.630882\n",
      "Epoch [90/100], Loss: 71.231995\n",
      "Epoch [90/100], Loss: 61.041504\n",
      "Epoch [90/100], Loss: 66.190109\n",
      "Epoch [100/100], Loss: 51.964294\n",
      "Epoch [100/100], Loss: 50.647369\n",
      "Epoch [100/100], Loss: 58.968616\n"
     ]
    }
   ],
   "source": [
    "#@ Training the model for 100 epochs\n",
    "fit(100, model, loss_fn, opt, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90d3ab4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 58.6014,  71.8464],\n",
       "        [ 81.6341,  95.4797],\n",
       "        [116.2578, 140.2192],\n",
       "        [ 30.0436,  46.8903],\n",
       "        [ 95.8716, 104.5114],\n",
       "        [ 57.5807,  70.8450],\n",
       "        [ 81.3277,  94.6336],\n",
       "        [116.5254, 140.3525],\n",
       "        [ 31.0642,  47.8918],\n",
       "        [ 96.5859, 104.6667],\n",
       "        [ 58.2950,  71.0003],\n",
       "        [ 80.6134,  94.4783],\n",
       "        [116.5642, 141.0653],\n",
       "        [ 29.3293,  46.7350],\n",
       "        [ 96.8923, 105.5128]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@ Generating predictions\n",
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ddbe3288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.],\n",
       "        [ 57.,  69.],\n",
       "        [ 80., 102.],\n",
       "        [118., 132.],\n",
       "        [ 21.,  38.],\n",
       "        [104., 118.],\n",
       "        [ 57.,  69.],\n",
       "        [ 82., 100.],\n",
       "        [118., 134.],\n",
       "        [ 20.,  38.],\n",
       "        [102., 120.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@ Comparing with targets\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df3b2b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[55.4564, 68.0069]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor([[75, 63, 44.]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7beb8d",
   "metadata": {},
   "source": [
    "The predicted yield of apples is 54.3 tons per hectare, and that orange is 68.3 tons per hectare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06900d85",
   "metadata": {},
   "source": [
    "**The End**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
